{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7Yv9kYonkHI"
   },
   "source": [
    "\n",
    "# Web Scraping for the Market Capitalization\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "### Importing modules \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mcQzAnHrV09E"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'parse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-09590bb3c54e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpdfplumber\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'parse'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import parse\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PyPDF2 import PdfFileWriter, PdfFileReader\n",
    "import textwrap\n",
    "import os\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from urllib.request import unquote\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import urllib.request\n",
    "from pdf2image import convert_from_path\n",
    "from pdf2image import convert_from_path\n",
    "import pymongo\n",
    "import base64\n",
    "import bson\n",
    "from bson.binary import Binary\n",
    "import gridfs\n",
    "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score, \n",
    "                             classification_report, f1_score, accuracy_score, average_precision_score, precision_recall_fscore_support)\n",
    "import mlxtend\n",
    "import os\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "chop = Options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scrapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_links():\n",
    "    options = Options()\n",
    "    options.add_argument(\"start-maximized\")\n",
    "    driver=webdriver.Chrome(chrome_options=options,executable_path=r\"C:\\Users\\HP\\Desktop\\Data Science\\Projet\\chromedriver.exe\")\n",
    "    driver.set_page_load_timeout(3000)\n",
    "    driver.get(\"http://www.maxulabourse.com.tn/fiche-valeur/TN0002300358\")\n",
    "    time.sleep(5)\n",
    "    lst = list()\n",
    "    select_box = driver.find_element_by_xpath('/html/body/div[2]/div[3]/div/div/div/div[1]/div[2]/select') \n",
    "    options = [x for x in select_box.find_elements_by_tag_name('option')]\n",
    "    for element in options:\n",
    "        lst.append({\"nom\" : element.text,\"lien\":\"http://www.maxulabourse.com.tn/fiche-valeur/\"+element.get_attribute(\"value\"),\"CB\":\"\"})\n",
    "    driver.quit()\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=collect_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes = namedtuple('ligne', 'Entreprise CapBoursiere')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "options = Options()\n",
    "options.add_argument(\"start-maximized\")\n",
    "driver=webdriver.Chrome(chrome_options=options,executable_path=r\"C:\\Users\\HP\\Desktop\\Data Science\\Projet\\chromedriver.exe\")\n",
    "driver.set_page_load_timeout(3000)\n",
    "for elem in links :\n",
    "    driver.get(elem[\"lien\"])\n",
    "    try:\n",
    "        driver.find_element_by_xpath('/html/body/div[2]/div[3]/div/div/div/div[5]/div/div[1]/div/ul/li[2]/a').click()\n",
    "        time.sleep(1)\n",
    "        d = driver.find_element_by_xpath('//*[@id=\"profile-1\"]/div/table/tbody/tr[3]/td[2]')\n",
    "        elem[\"CB\"]=d.text\n",
    "        l.append(colonnes(elem[\"nom\"],d.text))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CapBoursiere= pd.DataFrame(l)\n",
    "CapBoursiere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CapBoursiere.to_csv('CapBoursiere.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
